{% from 'physical-mcp10-dvr/underlay.yaml' import HOSTNAME_CFG01 with context %}
{% from 'physical-mcp10-dvr/underlay.yaml' import LAB_CONFIG_NAME with context %}
{% from 'physical-mcp10-dvr/underlay.yaml' import DOMAIN_NAME with context %}
{% from 'physical-mcp10-dvr/underlay.yaml' import HOSTNAME_KVM01 with context %}
{% from 'physical-mcp10-dvr/underlay.yaml' import HOSTNAME_KVM02 with context %}
{% from 'physical-mcp10-dvr/underlay.yaml' import HOSTNAME_KVM03 with context %}

{% set SALT_MODELS_REPOSITORY = os_env('SALT_MODELS_REPOSITORY','https://gerrit.mcp.mirantis.net/salt-models/mcp-baremetal-lab') %}
# Other salt model repository parameters see in shared-salt.yaml

# Name of the context file (without extension, that is fixed .yaml) used to render the Environment model
{% set ENVIRONMENT_MODEL_INVENTORY_NAME = os_env('ENVIRONMENT_MODEL_INVENTORY_NAME','physical-mcp10-dvr') %}
# Path to the context files used to render Cluster and Environment models
{%- set CLUSTER_CONTEXT_NAME = 'salt-context-cookiecutter-contrail-dpdk.yaml' %}
{%- set ENVIRONMENT_CONTEXT_NAMES = ['salt-context-environment.yaml','lab04-physical-inventory.yaml'] %}
{%- set CONTROL_VLAN = os_env('CONTROL_VLAN', '2422') %}
{%- set TENANT_VLAN = os_env('TENANT_VLAN', '2423') %}


{% import 'shared-salt.yaml' as SHARED with context %}

{{ SHARED.MACRO_INSTALL_SALT_MASTER() }}

{{ SHARED.MACRO_CLONE_RECLASS_MODELS() }}

{{ SHARED.MACRO_GENERATE_AND_ENABLE_ENVIRONMENT_MODEL() }}


### Modifying existing model
- description: Change cfg address
  cmd: |
    reclass-tools add-key parameters._param.infra_config_address 172.16.49.66 /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/init.yml;
    reclass-tools add-key parameters._param.infra_config_deploy_address 172.16.49.66 /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/init.yml;
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Change control network
  cmd: |
    files=`grep -rl "10.167.4" /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/`
    for i in $files; do sed -i 's/10\.167\.4\./10\.167\.8\./g' $i; done
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Change cluster public host to parametrized value
  cmd: |
    reclass-tools add-key parameters._param.cluster_public_host '${_param:openstack_proxy_address}' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/init.yml;
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Change cluster domain
  cmd: |
    reclass-tools add-key parameters._param.cluster_domain 'physical-mcp10-dvr.local' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/init.yml;
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Change infra kvm deploy addresses
  cmd: |
    reclass-tools add-key parameters._param.infra_kvm_node01_deploy_address 172.16.49.67 /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/init.yml;
    reclass-tools add-key parameters._param.infra_kvm_node02_deploy_address 172.16.49.68 /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/init.yml;
    reclass-tools add-key parameters._param.infra_kvm_node03_deploy_address 172.16.49.69 /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/init.yml;
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Adding required parameters in model
  cmd: |
    reclass-tools add-key parameters._param.dns_server01 8.8.8.8 /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/init.yml;
    reclass-tools add-key parameters._param.dns_server02 8.8.4.4 /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/init.yml;
    reclass-tools add-key parameters._param.control_network_netmask 255.255.255.0  /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/init.yml;
    reclass-tools add-key parameters._param.deploy_network_gateway 172.16.49.126 /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/init.yml;
    reclass-tools add-key parameters._param.control_vlan '2422' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/init.yml;
    reclass-tools add-key parameters._param.deploy_network_netmask 255.255.255.192 /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/init.yml;
    reclass-tools add-key parameters._param.salt_control_trusty_image 'http://images.mirantis.com/ubuntu-14-04-x64-mcp1.0.qcow2' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/init.yml;
    reclass-tools add-key parameters._param.salt_control_xenial_image 'http://images.mirantis.com/ubuntu-16-04-x64-mcp1.0.qcow2' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/init.yml;
    sed -i 's/br\-mgm/br\_mgm/g' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/kvm.yml;
    sed -i 's/br\-ctl/br\_ctl/g' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/kvm.yml;
    sed -i 's/linux\:/linux\:\n    system\:\n      service\:\n        apt\-daily\.timer\:\n          status: dead/g' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/infra/init.yml;
    sed -i 's/\-\ system\.ceph\.client\.single//g' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/openstack/control.yml;
    sed -i 's/\-\ system\.glance\.control\.storage\.ceph//g' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/openstack/control.yml;
    sed -i 's/\-\ system\.cinder\.control\.backend\.ceph//g' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/openstack/control.yml;
    sed -i 's/\-\ system\.cinder\.volume\.backend\.ceph//g' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/openstack/control.yml;
    sed -i 's/\-\ system\.ceph\.client\.single//g' /srv/salt/reclass/classes/cluster/physical-mcp10-dvr/openstack/compute.yml;
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

{{ SHARED.MACRO_CONFIGURE_RECLASS(FORMULA_SERVICES='"linux" "reclass" "salt" "openssh" "ntp" "git" "nginx" "collectd" "sensu" "heka" "sphinx" "keystone" "mysql" "grafana" "kibana" "haproxy" "rsyslog" "horizon" "prometheus" "telegraf" "elasticsearch" "powerdns" "glusterfs" "xtrabackup" "maas"') }}

- description: "Workaround for haproxy without listen"
  cmd: |
    set -e;
    git clone https://gerrit.mcp.mirantis.net/salt-formulas/haproxy;
    cd haproxy/;
    git fetch https://gerrit.mcp.mirantis.net/salt-formulas/haproxy refs/changes/39/11339/1 && git checkout FETCH_HEAD;
    cp haproxy/files/haproxy.cfg /srv/salt/env/prd/haproxy/files/;
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 10}
  skip_fail: true

{{ SHARED.MACRO_INSTALL_SALT_MINIONS() }}

- description: (REMOVE asap) Hack CFG of Hash sum mismatch
  cmd: |
    rm -rf /var/lib/apt/lists/*;
    apt-get clean;
    apt-get update;
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: true

{{ SHARED.MACRO_RUN_SALT_MASTER_UNDERLAY_STATES() }}

- description: "Workaround for rack01 compute generator"
  cmd: |
    set -e;
    # Remove rack01 key
    reclass-tools del-key parameters.reclass.storage.node.openstack_compute_rack01 /srv/salt/reclass/classes/cluster/{{ LAB_CONFIG_NAME }}/infra/config.yml;
    # Add openstack_compute_node definition from system
    reclass-tools add-key 'classes' 'system.reclass.storage.system.openstack_compute_multi' /srv/salt/reclass/classes/cluster/{{ LAB_CONFIG_NAME }}/infra/config.yml --merge;
    # Set ipaddresses
#    salt-call reclass.cluster_meta_set openstack_compute_node01_single_address 10.167.8.101 /srv/salt/reclass/classes/cluster/{{ LAB_CONFIG_NAME }}/infra/init.yml;
#    salt-call reclass.cluster_meta_set openstack_compute_node02_single_address 10.167.8.102 /srv/salt/reclass/classes/cluster/{{ LAB_CONFIG_NAME }}/infra/init.yml;
#    salt-call reclass.cluster_meta_set openstack_compute_node01_deploy_address 172.16.49.72 /srv/salt/reclass/classes/cluster/{{ LAB_CONFIG_NAME }}/infra/init.yml;
#    salt-call reclass.cluster_meta_set openstack_compute_node02_deploy_address 172.16.49.74 /srv/salt/reclass/classes/cluster/{{ LAB_CONFIG_NAME }}/infra/init.yml;

  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 10}
  skip_fail: false

{{ SHARED.MACRO_GENERATE_INVENTORY() }}

{{ SHARED.MACRO_NETWORKING_WORKAROUNDS() }}


- description: "Workaround for PROD-14060"
  cmd: |
    set -e;
    # Add tenant and single addresses for computes
    salt-call reclass.cluster_meta_set deploy_address 172.16.49.72 /srv/salt/reclass/nodes/_generated/cmp001.physical-mcp10-dvr.local.yml
    salt-call reclass.cluster_meta_set tenant_address 192.168.0.101 /srv/salt/reclass/nodes/_generated/cmp001.physical-mcp10-dvr.local.yml
    salt-call reclass.cluster_meta_set single_address 10.167.8.101 /srv/salt/reclass/nodes/_generated/cmp001.physical-mcp10-dvr.local.yml

    salt-call reclass.cluster_meta_set deploy_address 172.16.49.74 /srv/salt/reclass/nodes/_generated/cmp002.physical-mcp10-dvr.local.yml
    salt-call reclass.cluster_meta_set tenant_address 192.168.0.102 /srv/salt/reclass/nodes/_generated/cmp002.physical-mcp10-dvr.local.yml
    salt-call reclass.cluster_meta_set single_address 10.167.8.102 /srv/salt/reclass/nodes/_generated/cmp002.physical-mcp10-dvr.local.yml

  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 10}
  skip_fail: false


- description: Temporary workaround for removing cinder-volume from CTL nodes
  cmd: |
    sed -i 's/\-\ system\.cinder\.volume\.single//g' /srv/salt/reclass/classes/cluster/{{ LAB_CONFIG_NAME }}/openstack/control.yml;
    sed -i 's/\-\ system\.cinder\.volume\.notification\.messagingv2//g' /srv/salt/reclass/classes/cluster/{{ LAB_CONFIG_NAME }}/openstack/control.yml;
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: true

- description: Temporary WR (Remove ASAP) for downgrade packages
  cmd: |
    salt --hard-crash --state-output=mixed --state-verbose=False -C 'I@linux:system' state.sls linux.system.repo;
    salt --hard-crash --state-output=mixed --state-verbose=False -C 'I@linux:system' cmd.run "apt-get update"
    salt --hard-crash --state-output=mixed --state-verbose=False -C 'I@linux:system' cmd.run "apt-get install -y --allow-downgrades vlan";
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 10}
  skip_fail: true

{{ SHARED.MACRO_BOOTSTRAP_ALL_MINIONS() }}

########################################
# Spin up Control Plane VMs on KVM nodes
########################################

- description: Execute 'libvirt' states to create necessary libvirt networks
  cmd: salt --hard-crash --state-output=mixed --state-verbose=False 'kvm*' state.sls libvirt
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 2, delay: 10}
  skip_fail: false

- description: Create VMs for control plane
  cmd: salt --hard-crash --state-output=mixed --state-verbose=False 'kvm*' state.sls salt.control
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 3, delay: 10}
  skip_fail: false

- description: '*Workaround* for waiting the control-plane VMs in the salt-key (instead of sleep)'
  cmd: |
    salt-key -l acc| sort > /tmp/current_keys.txt &&
    salt 'kvm*' cmd.run 'virsh list --name' | grep -v 'kvm'|sort|xargs -I {} fgrep {} /tmp/current_keys.txt
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 20, delay: 30}
  skip_fail: false

#########################################
# Configure all running salt minion nodes
#########################################

- description: Hack resolv.conf on VCP nodes for internal services access
  cmd: |
    salt --hard-crash --state-output=mixed --state-verbose=False -C '* and not kvm* and not cmp* and not gtw* and not cfg*' cmd.run "echo 'nameserver 172.18.208.44' > /etc/resolv.conf;"
    salt --hard-crash --state-output=mixed --state-verbose=False -C '* and not kvm* and not cmp* and not gtw* and not cfg*' cmd.run "echo 'nameserver 8.8.8.8' >> /etc/resolv.conf;"
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Refresh pillars on all minions
  cmd: salt --hard-crash --state-output=mixed --state-verbose=False '*' saltutil.refresh_pillar
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Sync all salt resources
  cmd: salt --hard-crash --state-output=mixed --state-verbose=False '*' saltutil.sync_all && sleep 5
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Determine latest version of salt-minion
  cmd: |
    salt --timeout=300 '*' pkg.latest_version salt-minion
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 2, delay: 5}
  skip_fail: false

- description: Install latest version of salt-minion
  cmd: |
    salt --timeout=300 '*' pkg.install salt-minion
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 2, delay: 5}
  skip_fail: false

- description: Show  reclass-salt --top for generated nodes
  cmd: reclass-salt --top -u /srv/salt/reclass/nodes/_generated/
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Temporary WR (Remove ASAP) for downgrade packages
  cmd: |
    salt --hard-crash --state-output=mixed --state-verbose=False -C 'I@linux:system' state.sls linux.system.repo;
    salt --hard-crash --state-output=mixed --state-verbose=False -C 'I@linux:system' cmd.run "apt-get update"
    salt --hard-crash --state-output=mixed --state-verbose=False -C 'I@linux:system' cmd.run "apt-get install -y --allow-downgrades vlan";
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 10}
  skip_fail: true

- description: wait for apt-daily finished work (Temporary)
  cmd: sleep 600;
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Configure linux on other nodes
  cmd: salt --hard-crash --state-output=mixed --state-verbose=False -C 'I@linux:system' state.sls linux
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 5, delay: 10}
  skip_fail: false

- description: Configure openssh on all nodes
  cmd: salt --hard-crash --state-output=mixed --state-verbose=False -C 'I@linux:system and not cfg01*' state.sls openssh &&
    salt --hard-crash --state-output=mixed --state-verbose=False
    -C 'I@linux:system and not cfg01*' cmd.run "sed -i 's/PasswordAuthentication no/PasswordAuthentication
    yes/' /etc/ssh/sshd_config && service ssh reload"
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 5}
  skip_fail: false

- description: Configure salt.minion on other nodes
  cmd: |
    salt --timeout=120 --hard-crash --state-output=mixed --state-verbose=False -C 'I@linux:system and not cfg01*' state.sls salt.minion;
    sleep 60;
    jids=`salt '*' saltutil.running | grep -A1 "jid\:" | grep 2017 | uniq`;
    for jid in $jids; do
      salt '*' saltutil.kill_job $jid;
    done
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 3, delay: 15}
  skip_fail: true

{{ SHARED.MACRO_BOOTSTRAP_ALL_MINIONS() }}
