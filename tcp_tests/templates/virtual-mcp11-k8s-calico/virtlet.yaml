{% from 'virtual-mcp11-k8s-calico/underlay.yaml' import HOSTNAME_CTL02 with context %}
{% from 'virtual-mcp11-k8s-calico/underlay.yaml' import HOSTNAME_CFG01 with context %}

# Clone virtlet project from git to the ctl01 node for start virtlet pod from yaml
- description: Cloning virtlet project on ctl02
  cmd:  git clone -b master https://github.com/Mirantis/virtlet.git
  node_name: {{ HOSTNAME_CTL02 }}
  retry: {count: 1, delay: 1}
  skip_fail: false

# Add 'virtlet' label for ctl02
- description: Adding virtlet label for ctl02
  cmd:  kubectl label node ctl02 extraRuntime=virtlet
  node_name: {{ HOSTNAME_CTL02 }}
  retry: {count: 1, delay: 1}
  skip_fail: false

# Add route for internal kube-services if necessary
- description: Adding route for internal kube-services if necessary
  cmd: salt --hard-crash --state-output=mixed --state-verbose=False -C 'I@kubernetes:pool' cmd.run "ip r | grep 10.254 || ip ro add 10.254.0.0/16 dev ens4"
  node_name: {{ HOSTNAME_CFG01 }}
  retry: {count: 1, delay: 1}
  skip_fail: false


# Install jq
- description: Install jq
  cmd: apt-get install jq -y
  node_name: {{ HOSTNAME_CTL02 }}
  retry: {count: 1, delay: 1}
  skip_fail: false

# Add extra parameter for kubelet service on virtlet node
- description: Adding extra parameter for kubelet service on virtlet node
  cmd:  sed -i.bak "s|^\"|--feature-gates=DynamicKubeletConfig=true \\\\\\n\"|" /etc/default/kubelet
  node_name: {{ HOSTNAME_CTL02 }}
  retry: {count: 1, delay: 1}
  skip_fail: false

# Restart kubelet service on virtlet node
- description: Restart kubelet service on ctl02
  cmd:  systemctl restart kubelet
  node_name: {{ HOSTNAME_CTL02 }}
  retry: {count: 1, delay: 1}
  skip_fail: false

# Create virtlet pod
- description: Creating virtlet pod
  cmd: |
    kubectl convert -f virtlet/deploy/virtlet-ds.yaml --local -o json | jq \
    '.items[0].spec.template.spec.containers[0].env|=.+[{"name":"VIRTLET_DISABLE_KVM","value":"y"}] | .items[0].spec.template.spec.volumes|=.+[{"name":"etcd","hostPath":{"path":"/var/lib/etcd"}},{"name":"kubernetes","hostPath":{"path":"/etc/kubernetes"}}] | .items[0].spec.template.spec.containers[0].volumeMounts|=.+[{"mountPath":"/etc/kubernetes","name":"kubernetes"},{"mountPath":"/var/lib/etcd","name":"etcd"}]' | \
    kubectl create -f -
  node_name: {{ HOSTNAME_CTL02 }}
  retry: {count: 1, delay: 1}
  skip_fail: false

# Virtlet pod will likely stay in Init:0/1 state because there's a problem
# with automatic kubelet restart after applying the configmap.
# As of now, you'll need to restart kubelet after ~30-60 seconds.
- description: Restarting kubelet service on virtlet node
  cmd: |
    COUNTER=0
    while [[ $(kubectl get pods -n kube-system | awk '/virtlet/{print $3}') != 'Init:0/1' ]]; do
      COUNTER=$((COUNTER+1))
      sleep 5
      if [[ $COUNTER -eq 36 ]]; then
        echo "We havenot Init:0/1 state for virtlet pod. Aborting.";
        exit 1
      fi
    done
    sleep 60
    systemctl restart kubelet
  node_name: {{ HOSTNAME_CTL02 }}
  retry: {count: 1, delay: 1}
  skip_fail: false

# Wait Active state for virtlet pod
- description: Waiting 'Active' state for virtlet pod
  cmd: |
    COUNTER=0
    while [[ $(kubectl get pods -n kube-system | awk '/virtlet/{print $3}') != 'Running' ]]; do
      COUNTER=$((COUNTER+1))
      sleep 5
      if [[ $COUNTER -eq 36 ]]; then
        echo "We havenot Active state for virtlet pod. Aborting.";
        exit 1
      fi
    done
  node_name: {{ HOSTNAME_CTL02 }}
  retry: {count: 1, delay: 1}
  skip_fail: false
